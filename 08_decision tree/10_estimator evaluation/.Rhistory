library(caret)      # e.g. for confusion matrix
library(dplyr)      # data wrangling
library(CORElearn)  # data mining system
library(xtable)     # LaTex
dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/03_linearization/02_output/dataset_lin_1.csv",
sep = ";"
)
preparation <- function(dataset = dataset){
dataset <- dataset[2:ncol(dataset)]
dataset <- dataset %>%
mutate(
success = as.factor(success),
staat_d = as.factor(staat_d),
sex_m = as.factor(sex_m)
)
return(dataset)
}
dataset <- preparation(dataset)
rm(preparation)
est <- c(7, 10) # short version for testing
set.seed(2)
flag <- TRUE
for (j in est){
method = toString(infoCore(what = "attrEval")[j])
print(method)
# normal CV
ncases <- nrow(dataset)
ind <- ceiling(10*(1:ncases)/ncases)
ind <- sample(ind,length(ind))
pred <- rep(NA,ncases)
fit <- NULL
# run 10-fold cross validation
for (i in unique(ind)) {
# Delete the previous model, if there is one.
fit <- CoreModel(
f = success ~ .,
data = dataset[ind!=i,],
model= "tree",
selectionEstimator = infoCore(what = "attrEval")[j],
minNodeWeightTree = round(nrow(dataset)*0.00625)
)
pred[ind==i] <- predict(
fit,
dataset[ind==i,],
type="class" # options:
)
if (!is.null(fit)) destroyModels(fit) # dispose model no longer needed
}
# fit predicted vaules: 1 -> 0, 2 -> 1
pred <- as.data.frame(pred) %>%
mutate(pred = ifelse(pred == 1, 0, 1))
# create table with confusion matrix information
cm <- confusionMatrix(data = pred$pred, dataset$success)
core_eval <- modelEval(
model = fit,
correctClass = dataset$success,  # dataset$success
predictedClass = pred$pred
)
list <- data.frame(
"method" = infoCore(what = "attrEval")[j],
"AUC" = core_eval$AUC,
"avg cost" = core_eval$averageCost,
"ACC" = cm$overall["Accuracy"],
"P-Value" = cm$overall["AccuracyPValue"],
"FAL" = cm$table[1,2] / (cm$table[1,2] + cm$table[2,2]),
"SEN" = cm$byClass["Sensitivity"],
"SPE" = cm$byClass["Specificity"],
"PRE" = cm$byClass["Precision"],
"F1" = cm$byClass["F1"],
"F1,414" = 3*cm$byClass["Precision"]*cm$byClass["Sensitivity"] /
(2*cm$byClass["Precision"] + cm$byClass["Sensitivity"]),
"F2" = 5*cm$byClass["Precision"]*cm$byClass["Sensitivity"] /
(4*cm$byClass["Precision"] + cm$byClass["Sensitivity"]),
"KAP" = cm$overall["Kappa"],
"TP" = cm$table[1,1],
"TN" = cm$table[2,2],
"FP" = cm$table[1,2],
"FN" = cm$table[2,1]
)
if(flag){
cm_table <- data.frame(list)
} else {
cm_table <- bind_rows(cm_table, list[1,])
}
flag <- FALSE
}
rm(list, cm, core_eval, est, fit, flag, i, ind, j, method, ncases)
path <- "~/Desktop/Masterarbeit_local/08_decision tree/02_output/"
write.table(
cm_table,
file = paste(path, "dt_method_infos_exam.csv", sep = ""),
sep = ";",
dec = ",",
row.names = FALSE
)
x_method_infos <- xtable(
x = cm_table[, c(1, 4:10, 12:13)],
caption = "DT: Estimator Evaluation",
label = "table:dtMethodInfos",
auto = TRUE,
digits = 3
)
x_cm_results <- xtable(
x = cm_table[, c(1, 14:17)],
caption = "DT: Method Confusion Matrix",
label = "table:dtEstimatorEvaluation",
auto = TRUE,
digits = 3
)
print(x_method_infos, include.rownames=FALSE)
print(x_cm_results, include.rownames=FALSE)
rm(path)
rm(list = ls()) # clear workspace (optional)
source('~/Desktop/Masterarbeit_local/08_decision tree/10_estimator evaluation/81.01_exam1.R')
View(cm_table)
cm_table2 <- read.csv(
file = "~/Desktop/Masterarbeit_local/08_decision tree/02_output/dt_method_infos_exam.csv",
sep = ";",
dec = ","
)
