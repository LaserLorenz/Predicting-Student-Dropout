colnames_exams <- sort(colnames_exams)
# concat column names vectors
colnames <- c(colnames_core, colnames_exams)
# select columns following new order
output <- merge[,colnames]
print("Return linearized dataset")
return(output)
}
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams.csv",
sep = ";"
)
dataset <- backup %>%
filter(
sem <= 3,
success != 2
) %>%
mutate(
pstatus = ifelse(pstatus == 3, 2, pstatus)
)
dataset_core <- build_core(dataset)
View(dataset_core)
dataset <- semi_join(dataset, exam_dataset, by = "pnr") %>%
arrange(id)
print("Remove duplicate exams")
dataset <- dataset %>%
group_by(
id, pnr
) %>%
arrange(
sem
) %>%
filter(
row_number() == n()
)
dataset_core_sorted <- build_core(dataset)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams.csv",
sep = ";"
)
dataset <- backup %>%
filter(
sem <= 3,
success != 2
) %>%
mutate(
pstatus = ifelse(pstatus == 3, 2, pstatus)
)
dataset_core <- build_core(dataset)
dataset_core_sorted <- build_core(dataset)
dataset <- semi_join(dataset, exam_dataset, by = "pnr") %>%
arrange(id)
print("Remove duplicate exams")
dataset <- dataset %>%
group_by(
id, pnr
) %>%
arrange(
sem
) %>%
filter(
row_number() == n()
)
?left_join
View(dataset_core_sorted)
View(dataset_core)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams.csv",
sep = ";"
)
dataset <- backup %>%
filter(
sem <= 3,
success != 2
) %>%
mutate(
pstatus = ifelse(pstatus == 3, 2, pstatus)
)
dataset_core <- build_core(dataset)
View(dataset_core)
dataset_core <- dataset_core[, c(1:6, 10:11, 7:9)]
View(dataset_core)
dataset_core <- build_core(dataset)
View(dataset_core)
dataset_core <- build_core(dataset)
View(dataset_core)
build_core <- function(dataset = dataset){
core <- dataset %>%
group_by(
id,
success,
sex_m,
staat_d,
age
) %>%
summarise(
avg_note = mean(pnote),
count_sem = max(sem),
count_be = sum(pstatus == 1),
count_nb = sum(pstatus == 2)
) %>%
filter(
row_number() == 1
) %>%
select(
id,
success,
sex_m,
staat_d,
age,
avg_note,
count_sem,
count_be,
count_nb
) %>%
ungroup() %>%
mutate(
avg_be = ifelse(count_be != 0, count_be/count_sem, 0),
avg_nb = ifelse(count_nb != 0, count_nb/count_sem, 0)
)
# sort core dataset
dataset_core <- core[, c(1:6, 10:11, 7:9)]
return(dataset_core)
}
dataset_core <- build_core(dataset)
View(dataset_core)
print("Remove exams with too little observaitons")
dataset <- semi_join(dataset, exam_dataset, by = "pnr") %>%
arrange(id)
print("Remove duplicate exams")
dataset <- dataset %>%
group_by(
id, pnr
) %>%
arrange(
sem
) %>%
filter(
row_number() == n()
)
dataset_lin <- linearize(dataset, dataset_core, 0)
linearize <- function(dataset = dataset, core = dataset_core, fill_value = NA){
print("Create linearized subsets for each feature")
pnote <- dataset %>%
select(
id, pnr, pnote
) %>%
spread(
key = pnr,
value = pnote,
fill = fill_value
)
# add "_pnote" after the examnumber in colnames
colnames(pnote) <- paste(colnames(pnote), 'pnote', sep = "_")
# spread sem
sem <- dataset %>%
select(
id, pnr, sem
) %>%
spread(
key = pnr,
value = sem,
fill = fill_value
)
# add "_sem" after the examnumber in colnames
colnames(sem) <- paste(colnames(sem), 'sem', sep = "_")
# spread pversuch
pversuch <- dataset %>%
select(
id, pnr, pversuch
) %>%
spread(
key = pnr,
value = pversuch,
fill = fill_value
)
# add "_pversuch" after the examnumber in colnames
colnames(pversuch) <- paste(colnames(pversuch), 'pversuch', sep = "_")
print("Merge core data with linearized subsets")
# merge student with exam data
merge <- core %>%
left_join(
pnote,
by = c('id' = 'id_pnote')
) %>% left_join(
sem,
by = c('id' = 'id_sem')
) %>% left_join(
pversuch,
by = c('id' = 'id_pversuch')
)
print("Arrange columns in correct order")
# arrange columns by examnumber
# save core column names
colnames_core <- names(merge)[1:11]
# save exam column names
colnames_exams <- names(merge)[12:length(names(merge))]
# sort exam column names
colnames_exams <- sort(colnames_exams)
# concat column names vectors
colnames <- c(colnames_core, colnames_exams)
# select columns following new order
output <- merge[,colnames]
print("Return linearized dataset")
return(output)
}
dataset_lin <- linearize(dataset = dataset, coredataset_core, 0)
dataset_lin <- linearize(dataset, dataset_core, 0)
View(dataset_lin)
View(dataset_core)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams.csv",
sep = ";"
)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams.csv",
sep = ";"
)
build_core <- function(dataset = dataset){
core <- dataset %>%
group_by(
id,
success,
sex_m,
staat_d,
age
) %>%
summarise(
avg_note = mean(pnote),
count_sem = max(sem),
count_be = sum(pstatus == 1),
count_nb = sum(pstatus == 2)
) %>%
filter(
row_number() == 1
) %>%
select(
id,
success,
sex_m,
staat_d,
age,
avg_note,
count_sem,
count_be,
count_nb
) %>%
ungroup() %>%
mutate(
avg_be = ifelse(count_be != 0, count_be/count_sem, 0),
avg_nb = ifelse(count_nb != 0, count_nb/count_sem, 0)
)
# sort core dataset
dataset_core <- core[, c(1:6, 10:11, 7:9)]
return(dataset_core)
}
linearize <- function(dataset = dataset, core = dataset_core, fill_value = NA){
print("Create linearized subsets for each feature")
pnote <- dataset %>%
select(
id, pnr, pnote
) %>%
spread(
key = pnr,
value = pnote,
fill = fill_value
)
# add "_pnote" after the examnumber in colnames
colnames(pnote) <- paste(colnames(pnote), 'pnote', sep = "_")
# spread sem
sem <- dataset %>%
select(
id, pnr, sem
) %>%
spread(
key = pnr,
value = sem,
fill = fill_value
)
# add "_sem" after the examnumber in colnames
colnames(sem) <- paste(colnames(sem), 'sem', sep = "_")
# spread pversuch
pversuch <- dataset %>%
select(
id, pnr, pversuch
) %>%
spread(
key = pnr,
value = pversuch,
fill = fill_value
)
# add "_pversuch" after the examnumber in colnames
colnames(pversuch) <- paste(colnames(pversuch), 'pversuch', sep = "_")
print("Merge core data with linearized subsets")
# merge student with exam data
merge <- core %>%
left_join(
pnote,
by = c('id' = 'id_pnote')
) %>% left_join(
sem,
by = c('id' = 'id_sem')
) %>% left_join(
pversuch,
by = c('id' = 'id_pversuch')
)
print("Arrange columns in correct order")
# arrange columns by examnumber
# save core column names
colnames_core <- names(merge)[1:11]
# save exam column names
colnames_exams <- names(merge)[12:length(names(merge))]
# sort exam column names
colnames_exams <- sort(colnames_exams)
# concat column names vectors
colnames <- c(colnames_core, colnames_exams)
# select columns following new order
output <- merge[,colnames]
print("Return linearized dataset")
return(output)
}
dataset <- backup %>%
filter(
sem <= 3,
success != 2
) %>%
mutate(
pstatus = ifelse(pstatus == 3, 2, pstatus)
)
dataset_core <- build_core(dataset)
print("Remove exams with too little observaitons")
dataset <- semi_join(dataset, exam_dataset, by = "pnr") %>%
arrange(id)
print("Remove duplicate exams")
dataset <- dataset %>%
group_by(
id, pnr
) %>%
arrange(
sem
) %>%
filter(
row_number() == n()
)
print("Linearize features")
dataset_lin <- linearize(dataset, dataset_core, 0)
path <- "~/Desktop/Masterarbeit_local/03_linearization/02_output/"
print("Export linearized dataset to:")
print(path)
write.table(
dataset_lin,
file = paste(path, "dataset_lin.csv", sep = ""),
sep = ";",
row.names = FALSE
)
print("Output complete")
rm(
backup,
path,
linearize,
exam_dataset,
dataset
)
rm(
backup,
path,
linearize,
build_core,
exam_dataset,
dataset,
dataset_core
)
library('caret')
dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/03_linearization/02_output/dataset_lin.csv",
sep = ";"
)
rm(dataset_lin)
expl_vars <- dataset[, c(3:ncol(dataset))]
corr_expl_vars = cor(expl_vars)
hc = findCorrelation(corr_expl_vars, cutoff = 0.8, verbose = F, names = F, exact = T)
hc = sort(hc)
expl_vars <- dataset[, c(3:ncol(dataset))]
print("Calculated correlation matrix and delete variables corr > 0.8")
corr_expl_vars = cor(expl_vars)
hc = findCorrelation(corr_expl_vars, cutoff = 0.8, verbose = F, names = F, exact = T)
View(corr_expl_vars)
View(dataset)
dataset <- read.csv(
file = "~/Desktop/Masterarbeit_local/03_linearization/02_output/dataset_lin.csv",
sep = ";"
)
print("Preprocess data")
expl_vars <- dataset[, c(3:ncol(dataset))]
View(expl_vars)
print("Calculated correlation matrix and delete variables corr > 0.8")
corr_expl_vars = cor(expl_vars)
View(corr_expl_vars)
exam_dataset_1 <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams_1.csv",
sep = ";"
)
View(exam_dataset_1)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
library(dplyr)
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
View(backup)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n())
View(stateanalysis)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1)
View(stateanalysis)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1, success == 0)
View(stateanalysis)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1, success == 0) %>%
group_by(staat_d) %>%
summarise(count_staat = n())
View(stateanalysis)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1) %>%
group_by(staat_d) %>%
summarise(count_staat = n())
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1) %>%
group_by(staat_d, success) %>%
summarise(count_staat = n())
View(stateanalysis)
stateanalysis <- backup %>%
group_by(id, staat_d, success, sem) %>%
summarise(count = n()) %>%
filter(sem == 1, success != 2) %>%
group_by(staat_d, success) %>%
summarise(count_staat = n())
View(stateanalysis)
write.table(
stateanalysis,
file = "~/Desktop/Masterarbeit_local/01_database preparation/02_output/04_interim results/state analysis.csv",
sep = ";",
row.names = FALSE
)
write.table(
stateanalysis,
file = "~/Desktop/Masterarbeit_local/01_database preparation/04_interim results/state analysis.csv",
sep = ";",
row.names = FALSE
)
library(dplyr)        # data wrangling
library(tidyr)        # data wrangling
print("Read input data from preanalysis")
backup <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/dataset.csv",
sep = ";"
)
exam_dataset_1 <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams_1.csv",
sep = ";"
)
exam_dataset_2 <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams_2.csv",
sep = ";"
)
exam_dataset_3 <- read.csv(
file = "~/Desktop/Masterarbeit_local/02_preanalysis/02_output/exams_3.csv",
sep = ";"
)
View(exam_dataset_3)
View(backup)
View(backup %>% group_by(pnr) %>% summarise(count = n()))
